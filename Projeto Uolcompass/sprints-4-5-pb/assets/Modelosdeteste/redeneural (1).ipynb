{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482efbb0-b52d-4090-aeb4-c8ca7c66abbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (1.7.6)\n",
      "Requirement already satisfied: pymysql in /opt/conda/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (2.0.30)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.35.9)\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.230.0)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (0.12.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.24.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (71.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.9 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.35.9)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.10/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.17.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.2.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.66.4)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.26.19)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.19.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (2024.7.4)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.20.0)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "\u001b[33mWARNING: Error parsing requirements for fsspec: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/fsspec-2023.6.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn tensorflow xgboost pymysql python-dotenv sqlalchemy boto3 sagemaker imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d7fdd8-d787-42b7-90fb-928202abe52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 02:31:30.556659: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Todas as bibliotecas foram importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import xgboost as xgb\n",
    "import pymysql\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import boto3\n",
    "from io import StringIO\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost import XGBoost\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"Todas as bibliotecas foram importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e16cf063-8dc7-4f30-a0fa-2117c81e99ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para classificar o preço\n",
    "def classify_price(price):\n",
    "    if price <= 85:\n",
    "        return 1\n",
    "    elif price > 85 and price < 115:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd45d22-7dc4-4e59-8162-8bcf2db2d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Booking_ID  no_of_adults  no_of_children  no_of_weekend_nights  \\\n",
      "0   INN00001             2               0                     1   \n",
      "1   INN00002             2               0                     2   \n",
      "2   INN00003             1               0                     2   \n",
      "3   INN00004             2               0                     0   \n",
      "4   INN00005             2               0                     1   \n",
      "\n",
      "   no_of_week_nights type_of_meal_plan  required_car_parking_space  \\\n",
      "0                  2       Meal Plan 1                           0   \n",
      "1                  3      Not Selected                           0   \n",
      "2                  1       Meal Plan 1                           0   \n",
      "3                  2       Meal Plan 1                           0   \n",
      "4                  1      Not Selected                           0   \n",
      "\n",
      "  room_type_reserved  lead_time  arrival_year  arrival_month  arrival_date  \\\n",
      "0        Room_Type 1        224          2017             10             2   \n",
      "1        Room_Type 1          5          2018             11             6   \n",
      "2        Room_Type 1          1          2018              2            28   \n",
      "3        Room_Type 1        211          2018              5            20   \n",
      "4        Room_Type 1         48          2018              4            11   \n",
      "\n",
      "  market_segment_type  repeated_guest  no_of_previous_cancellations  \\\n",
      "0             Offline               0                             0   \n",
      "1              Online               0                             0   \n",
      "2              Online               0                             0   \n",
      "3              Online               0                             0   \n",
      "4              Online               0                             0   \n",
      "\n",
      "   no_of_previous_bookings_not_canceled  avg_price_per_room  \\\n",
      "0                                     0               65.00   \n",
      "1                                     0              106.68   \n",
      "2                                     0               60.00   \n",
      "3                                     0              100.00   \n",
      "4                                     0               94.50   \n",
      "\n",
      "   no_of_special_requests booking_status  \n",
      "0                       0   Not_Canceled  \n",
      "1                       1   Not_Canceled  \n",
      "2                       0       Canceled  \n",
      "3                       0       Canceled  \n",
      "4                       0       Canceled  \n",
      "   label_avg_price_per_room  no_of_adults  no_of_children  \\\n",
      "0                         1             2               0   \n",
      "1                         2             2               0   \n",
      "2                         1             1               0   \n",
      "3                         2             2               0   \n",
      "4                         2             2               0   \n",
      "\n",
      "   no_of_weekend_nights  no_of_week_nights type_of_meal_plan  \\\n",
      "0                     1                  2       Meal Plan 1   \n",
      "1                     2                  3      Not Selected   \n",
      "2                     2                  1       Meal Plan 1   \n",
      "3                     0                  2       Meal Plan 1   \n",
      "4                     1                  1      Not Selected   \n",
      "\n",
      "   required_car_parking_space room_type_reserved  lead_time  arrival_year  \\\n",
      "0                           0        Room_Type 1        224          2017   \n",
      "1                           0        Room_Type 1          5          2018   \n",
      "2                           0        Room_Type 1          1          2018   \n",
      "3                           0        Room_Type 1        211          2018   \n",
      "4                           0        Room_Type 1         48          2018   \n",
      "\n",
      "   arrival_month  arrival_date market_segment_type  repeated_guest  \\\n",
      "0             10             2             Offline               0   \n",
      "1             11             6              Online               0   \n",
      "2              2            28              Online               0   \n",
      "3              5            20              Online               0   \n",
      "4              4            11              Online               0   \n",
      "\n",
      "   no_of_special_requests  \n",
      "0                       0  \n",
      "1                       1  \n",
      "2                       0  \n",
      "3                       0  \n",
      "4                       0  \n"
     ]
    }
   ],
   "source": [
    "# Carrega as variáveis de ambiente do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Recupera as configurações de conexão das variáveis de ambiente\n",
    "host = os.getenv('DB_HOST')\n",
    "port = int(os.getenv('DB_PORT'))\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "database = os.getenv('DB_NAME')\n",
    "\n",
    "# Criação do engine para conectar ao banco de dados\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "# Estabelece a conexão com o banco de dados\n",
    "try:\n",
    "    # Consulta SQL para selecionar dados da tabela desejada\n",
    "    query = \"SELECT * FROM base_hotel\"\n",
    "\n",
    "    # Carrega os dados no DataFrame chamado base_hotel usando o engine\n",
    "    base_hotel = pd.read_sql_query(query, engine)\n",
    "    \n",
    "    # Exibe as primeiras linhas do DataFrame para verificar\n",
    "    print(base_hotel.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao conectar ou executar a consulta: {e}\")\n",
    "\n",
    "# Criar a coluna de label\n",
    "base_hotel['label_avg_price_per_room'] = base_hotel['avg_price_per_room'].apply(classify_price)\n",
    "\n",
    "# Remover a coluna avg_price_per_room\n",
    "base_hotel = base_hotel.drop(columns=['avg_price_per_room'])\n",
    "\n",
    "# Reorganizar as colunas para que 'label_avg_price_per_room' seja a primeira\n",
    "columns_order = ['label_avg_price_per_room'] + [col for col in base_hotel.columns if col != 'label_avg_price_per_room']\n",
    "base_hotel = base_hotel[columns_order]\n",
    "\n",
    "# Lista de colunas que você deseja remover\n",
    "colunas_para_remover = ['Booking_ID','no_of_previous_cancellations', \n",
    "                        'no_of_previous_bookings_not_canceled', \n",
    "                        'booking_status']\n",
    "\n",
    "# Filtrar as colunas que realmente existem no DataFrame\n",
    "colunas_existentes = [col for col in colunas_para_remover if col in base_hotel.columns]\n",
    "\n",
    "# Remover colunas existentes\n",
    "base_hotel.drop(columns=colunas_existentes, axis=1, inplace=True)\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "print(base_hotel.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca016acf-cd79-4eb5-85d8-c4c76a340d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame codificado:\n",
      "   label_avg_price_per_room  no_of_adults  no_of_children  \\\n",
      "0                         1             2               0   \n",
      "1                         2             2               0   \n",
      "2                         1             1               0   \n",
      "3                         2             2               0   \n",
      "4                         2             2               0   \n",
      "\n",
      "   no_of_weekend_nights  no_of_week_nights  lead_time  arrival_date  \\\n",
      "0                     1                  2        224             2   \n",
      "1                     2                  3          5             6   \n",
      "2                     2                  1          1            28   \n",
      "3                     0                  2        211            20   \n",
      "4                     1                  1         48            11   \n",
      "\n",
      "   market_segment_type  repeated_guest  type_of_meal_plan_1  ...  \\\n",
      "0                    3               0                  0.0  ...   \n",
      "1                    4               0                  0.0  ...   \n",
      "2                    4               0                  0.0  ...   \n",
      "3                    4               0                  0.0  ...   \n",
      "4                    4               0                  0.0  ...   \n",
      "\n",
      "   arrival_month_9  arrival_month_10  arrival_month_11  arrival_month_12  \\\n",
      "0            False              True             False             False   \n",
      "1            False             False              True             False   \n",
      "2            False             False             False             False   \n",
      "3            False             False             False             False   \n",
      "4            False             False             False             False   \n",
      "\n",
      "   no_of_special_requests_0  no_of_special_requests_1  \\\n",
      "0                      True                     False   \n",
      "1                     False                      True   \n",
      "2                      True                     False   \n",
      "3                      True                     False   \n",
      "4                      True                     False   \n",
      "\n",
      "   no_of_special_requests_2  no_of_special_requests_3  \\\n",
      "0                     False                     False   \n",
      "1                     False                     False   \n",
      "2                     False                     False   \n",
      "3                     False                     False   \n",
      "4                     False                     False   \n",
      "\n",
      "   no_of_special_requests_4  no_of_special_requests_5  \n",
      "0                     False                     False  \n",
      "1                     False                     False  \n",
      "2                     False                     False  \n",
      "3                     False                     False  \n",
      "4                     False                     False  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "Dimensões do conjunto de treinamento: (17836, 40), (17836,)\n",
      "Dimensões do conjunto de teste: (7644, 40), (7644,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "# Tratamento de colunas categóricas usando Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "base_hotel['type_of_meal_plan'] = label_encoder.fit_transform(base_hotel['type_of_meal_plan'])\n",
    "base_hotel['room_type_reserved'] = label_encoder.fit_transform(base_hotel['room_type_reserved'])\n",
    "base_hotel['market_segment_type'] = label_encoder.fit_transform(base_hotel['market_segment_type'])\n",
    "\n",
    "# Aplicar One-Hot Encoding\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "meal_plan_encoded = one_hot_encoder.fit_transform(base_hotel[['type_of_meal_plan']])\n",
    "meal_plan_df = pd.DataFrame(meal_plan_encoded, columns=one_hot_encoder.get_feature_names_out(['type_of_meal_plan']))\n",
    "base_hotel = pd.concat([base_hotel, meal_plan_df], axis=1)\n",
    "base_hotel.drop(['type_of_meal_plan'], axis=1, inplace=True)\n",
    "\n",
    "# Imputação de valores faltantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "base_hotel[['label_avg_price_per_room']] = imputer.fit_transform(base_hotel[['label_avg_price_per_room']])\n",
    "\n",
    "# Convertendo valores para inteiros\n",
    "base_hotel['label_avg_price_per_room'] = base_hotel['label_avg_price_per_room'].astype(int)\n",
    "\n",
    "# Tratamento de colunas de data\n",
    "base_hotel['arrival_date'] = base_hotel['arrival_date'].astype(int)\n",
    "base_hotel['arrival_month'] = base_hotel['arrival_month'].astype(int)\n",
    "base_hotel['arrival_year'] = base_hotel['arrival_year'].astype(int)\n",
    "\n",
    "# Remoção de colunas redundantes se houver\n",
    "base_hotel.drop_duplicates(inplace=True)\n",
    "\n",
    "# Aplicar One-Hot Encoding para variáveis categóricas restantes\n",
    "base_hotel_encoded = pd.get_dummies(base_hotel, columns=['required_car_parking_space', 'room_type_reserved', 'arrival_year', 'arrival_month', 'no_of_special_requests'])\n",
    "\n",
    "# Extrair as features (X) e o target (Y) do DataFrame codificado\n",
    "X = base_hotel_encoded.drop(columns=['label_avg_price_per_room']).values  # Features (excluindo o target)\n",
    "Y = base_hotel_encoded['label_avg_price_per_room'].values  # Target\n",
    "\n",
    "# Codificar o target Y para inteiros consecutivos\n",
    "label_encoder = LabelEncoder()\n",
    "Y_encoded = label_encoder.fit_transform(Y)\n",
    "\n",
    "# Dividir o conjunto de dados em treinamento e teste\n",
    "X_treinamento, X_teste, Y_treinamento, Y_teste = train_test_split(X, Y_encoded, test_size=0.3, random_state=1, stratify=Y_encoded)\n",
    "\n",
    "# Exibir o DataFrame codificado\n",
    "print(\"DataFrame codificado:\")\n",
    "print(base_hotel_encoded.head())\n",
    "\n",
    "# Exibir as dimensões dos conjuntos de dados\n",
    "print(f\"Dimensões do conjunto de treinamento: {X_treinamento.shape}, {Y_treinamento.shape}\")\n",
    "print(f\"Dimensões do conjunto de teste: {X_teste.shape}, {Y_teste.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bad8afb-4ef9-4d69-bcf5-fb079afc097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame codificado:\n",
      "   label_avg_price_per_room  no_of_adults  no_of_children  \\\n",
      "0                         1             2               0   \n",
      "1                         2             2               0   \n",
      "2                         1             1               0   \n",
      "3                         2             2               0   \n",
      "4                         2             2               0   \n",
      "\n",
      "   no_of_weekend_nights  no_of_week_nights  lead_time  arrival_date  \\\n",
      "0                     1                  2        224             2   \n",
      "1                     2                  3          5             6   \n",
      "2                     2                  1          1            28   \n",
      "3                     0                  2        211            20   \n",
      "4                     1                  1         48            11   \n",
      "\n",
      "   market_segment_type  repeated_guest  type_of_meal_plan_1  ...  \\\n",
      "0                    3               0                  0.0  ...   \n",
      "1                    4               0                  0.0  ...   \n",
      "2                    4               0                  0.0  ...   \n",
      "3                    4               0                  0.0  ...   \n",
      "4                    4               0                  0.0  ...   \n",
      "\n",
      "   arrival_month_9  arrival_month_10  arrival_month_11  arrival_month_12  \\\n",
      "0            False              True             False             False   \n",
      "1            False             False              True             False   \n",
      "2            False             False             False             False   \n",
      "3            False             False             False             False   \n",
      "4            False             False             False             False   \n",
      "\n",
      "   no_of_special_requests_0  no_of_special_requests_1  \\\n",
      "0                      True                     False   \n",
      "1                     False                      True   \n",
      "2                      True                     False   \n",
      "3                      True                     False   \n",
      "4                      True                     False   \n",
      "\n",
      "   no_of_special_requests_2  no_of_special_requests_3  \\\n",
      "0                     False                     False   \n",
      "1                     False                     False   \n",
      "2                     False                     False   \n",
      "3                     False                     False   \n",
      "4                     False                     False   \n",
      "\n",
      "   no_of_special_requests_4  no_of_special_requests_5  \n",
      "0                     False                     False  \n",
      "1                     False                     False  \n",
      "2                     False                     False  \n",
      "3                     False                     False  \n",
      "4                     False                     False  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "Tabela 'base_hotel_modified3' criada e salva com sucesso no banco de dados.\n"
     ]
    }
   ],
   "source": [
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_treinamento = scaler.fit_transform(X_treinamento)\n",
    "X_teste = scaler.transform(X_teste)\n",
    "\n",
    "# Exibir o DataFrame codificado\n",
    "print(\"DataFrame codificado:\")\n",
    "print(base_hotel_encoded.head())\n",
    "\n",
    "# Nome da nova tabela\n",
    "table_name = 'base_hotel_modified3'\n",
    "\n",
    "# Salvar o DataFrame em uma nova tabela no banco de dados\n",
    "base_hotel.to_sql(name=table_name, con=engine, if_exists='replace', index=False)\n",
    "print(f\"Tabela '{table_name}' criada e salva com sucesso no banco de dados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef57f9ed-6f1c-4383-9c86-b2fc63f86bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos das classes: {0: 1.1297330850403475, 1: 0.9549509032306424, 2: 0.9366269666225555}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Calcular pesos das classes\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(Y_encoded), y=Y_encoded)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"Pesos das classes: {class_weights_dict}\")\n",
    "\n",
    "# Construir o modelo de Redes Neurais Profundas\n",
    "model = Sequential()\n",
    "\n",
    "# Camada de entrada\n",
    "model.add(Dense(128, input_shape=(X_treinamento.shape[1],), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  # Aumentar o dropout para combater overfitting\n",
    "\n",
    "# Camada oculta 1\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  # Aumentar o dropout para combater overfitting\n",
    "\n",
    "# Camada oculta 2\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  # Aumentar o dropout para combater overfitting\n",
    "\n",
    "# Camada oculta 3 (adicional)\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  # Aumentar o dropout para combater overfitting\n",
    "\n",
    "# Camada de saída\n",
    "num_classes = len(np.unique(Y_encoded))  # Ajuste o número de classes conforme necessário\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),  # Reduzir a taxa de aprendizado\n",
    "              loss='sparse_categorical_crossentropy',  # Usar 'sparse_categorical_crossentropy' para classes inteiras\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e6f5372-c610-47c0-b0be-be5d59ca6cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/223 [==============================] - 5s 9ms/step - loss: 1.2671 - accuracy: 0.3943 - val_loss: 0.9667 - val_accuracy: 0.5266\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 1.0286 - accuracy: 0.4829 - val_loss: 0.8606 - val_accuracy: 0.5743\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.9229 - accuracy: 0.5487 - val_loss: 0.7936 - val_accuracy: 0.6334\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.8663 - accuracy: 0.5931 - val_loss: 0.7511 - val_accuracy: 0.6707\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.8276 - accuracy: 0.6115 - val_loss: 0.7261 - val_accuracy: 0.6777\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.8046 - accuracy: 0.6285 - val_loss: 0.7103 - val_accuracy: 0.6811\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.7803 - accuracy: 0.6468 - val_loss: 0.6977 - val_accuracy: 0.6883\n",
      "Epoch 8/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.7742 - accuracy: 0.6530 - val_loss: 0.6877 - val_accuracy: 0.7004\n",
      "Epoch 9/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.7598 - accuracy: 0.6602 - val_loss: 0.6815 - val_accuracy: 0.6996\n",
      "Epoch 10/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.7488 - accuracy: 0.6661 - val_loss: 0.6725 - val_accuracy: 0.7054\n",
      "Epoch 11/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.7441 - accuracy: 0.6681 - val_loss: 0.6682 - val_accuracy: 0.7091\n",
      "Epoch 12/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.7381 - accuracy: 0.6740 - val_loss: 0.6642 - val_accuracy: 0.7124\n",
      "Epoch 13/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.7303 - accuracy: 0.6753 - val_loss: 0.6551 - val_accuracy: 0.7147\n",
      "Epoch 14/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.7283 - accuracy: 0.6779 - val_loss: 0.6527 - val_accuracy: 0.7161\n",
      "Epoch 15/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.7168 - accuracy: 0.6845 - val_loss: 0.6486 - val_accuracy: 0.7195\n",
      "Epoch 16/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.7120 - accuracy: 0.6876 - val_loss: 0.6445 - val_accuracy: 0.7209\n",
      "Epoch 17/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.7070 - accuracy: 0.6956 - val_loss: 0.6412 - val_accuracy: 0.7239\n",
      "Epoch 18/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.7008 - accuracy: 0.6927 - val_loss: 0.6344 - val_accuracy: 0.7225\n",
      "Epoch 19/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.7034 - accuracy: 0.6954 - val_loss: 0.6320 - val_accuracy: 0.7279\n",
      "Epoch 20/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.6963 - val_loss: 0.6304 - val_accuracy: 0.7225\n",
      "Epoch 21/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.6957 - accuracy: 0.6998 - val_loss: 0.6271 - val_accuracy: 0.7245\n",
      "Epoch 22/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6897 - accuracy: 0.7027 - val_loss: 0.6245 - val_accuracy: 0.7315\n",
      "Epoch 23/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.6851 - accuracy: 0.7062 - val_loss: 0.6214 - val_accuracy: 0.7265\n",
      "Epoch 24/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6760 - accuracy: 0.7090 - val_loss: 0.6152 - val_accuracy: 0.7343\n",
      "Epoch 25/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6812 - accuracy: 0.7042 - val_loss: 0.6139 - val_accuracy: 0.7408\n",
      "Epoch 26/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6724 - accuracy: 0.7123 - val_loss: 0.6085 - val_accuracy: 0.7405\n",
      "Epoch 27/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6717 - accuracy: 0.7130 - val_loss: 0.6050 - val_accuracy: 0.7408\n",
      "Epoch 28/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6697 - accuracy: 0.7091 - val_loss: 0.6054 - val_accuracy: 0.7410\n",
      "Epoch 29/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6676 - accuracy: 0.7166 - val_loss: 0.6051 - val_accuracy: 0.7427\n",
      "Epoch 30/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6627 - accuracy: 0.7224 - val_loss: 0.6012 - val_accuracy: 0.7480\n",
      "Epoch 31/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6664 - accuracy: 0.7194 - val_loss: 0.6000 - val_accuracy: 0.7447\n",
      "Epoch 32/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.6589 - accuracy: 0.7197 - val_loss: 0.5979 - val_accuracy: 0.7475\n",
      "Epoch 33/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6561 - accuracy: 0.7194 - val_loss: 0.5980 - val_accuracy: 0.7466\n",
      "Epoch 34/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6565 - accuracy: 0.7237 - val_loss: 0.5960 - val_accuracy: 0.7427\n",
      "Epoch 35/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6596 - accuracy: 0.7262 - val_loss: 0.5960 - val_accuracy: 0.7416\n",
      "Epoch 36/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6503 - accuracy: 0.7267 - val_loss: 0.5898 - val_accuracy: 0.7466\n",
      "Epoch 37/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6513 - accuracy: 0.7278 - val_loss: 0.5883 - val_accuracy: 0.7480\n",
      "Epoch 38/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6426 - accuracy: 0.7318 - val_loss: 0.5865 - val_accuracy: 0.7550\n",
      "Epoch 39/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6511 - accuracy: 0.7327 - val_loss: 0.5879 - val_accuracy: 0.7461\n",
      "Epoch 40/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6476 - accuracy: 0.7297 - val_loss: 0.5867 - val_accuracy: 0.7545\n",
      "Epoch 41/100\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.6475 - accuracy: 0.7310 - val_loss: 0.5859 - val_accuracy: 0.7522\n",
      "Epoch 42/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6488 - accuracy: 0.7281 - val_loss: 0.5871 - val_accuracy: 0.7489\n",
      "Epoch 43/100\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.6493 - accuracy: 0.7309 - val_loss: 0.5866 - val_accuracy: 0.7548\n",
      "Epoch 44/100\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.6401 - accuracy: 0.7344 - val_loss: 0.5831 - val_accuracy: 0.7508\n",
      "Epoch 45/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6429 - accuracy: 0.7340 - val_loss: 0.5835 - val_accuracy: 0.7548\n",
      "Epoch 46/100\n",
      "223/223 [==============================] - 1s 3ms/step - loss: 0.6427 - accuracy: 0.7311 - val_loss: 0.5810 - val_accuracy: 0.7584\n",
      "Epoch 47/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6383 - accuracy: 0.7366 - val_loss: 0.5804 - val_accuracy: 0.7492\n",
      "Epoch 48/100\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.6436 - accuracy: 0.7351 - val_loss: 0.5794 - val_accuracy: 0.7553\n",
      "Epoch 49/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.6288 - accuracy: 0.7390 - val_loss: 0.5788 - val_accuracy: 0.7576\n",
      "Epoch 50/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.6325 - accuracy: 0.7393 - val_loss: 0.5783 - val_accuracy: 0.7559\n",
      "Epoch 51/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6290 - accuracy: 0.7383 - val_loss: 0.5758 - val_accuracy: 0.7607\n",
      "Epoch 52/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6269 - accuracy: 0.7402 - val_loss: 0.5808 - val_accuracy: 0.7511\n",
      "Epoch 53/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6274 - accuracy: 0.7395 - val_loss: 0.5763 - val_accuracy: 0.7553\n",
      "Epoch 54/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.7426 - val_loss: 0.5795 - val_accuracy: 0.7573\n",
      "Epoch 55/100\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.6328 - accuracy: 0.7399 - val_loss: 0.5767 - val_accuracy: 0.7550\n",
      "Epoch 56/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6292 - accuracy: 0.7408 - val_loss: 0.5742 - val_accuracy: 0.7570\n",
      "Epoch 57/100\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.6265 - accuracy: 0.7410 - val_loss: 0.5726 - val_accuracy: 0.7564\n",
      "Epoch 58/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.6247 - accuracy: 0.7384 - val_loss: 0.5718 - val_accuracy: 0.7612\n",
      "Epoch 59/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6254 - accuracy: 0.7403 - val_loss: 0.5731 - val_accuracy: 0.7559\n",
      "Epoch 60/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6234 - accuracy: 0.7473 - val_loss: 0.5721 - val_accuracy: 0.7553\n",
      "Epoch 61/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6231 - accuracy: 0.7444 - val_loss: 0.5699 - val_accuracy: 0.7578\n",
      "Epoch 62/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6208 - accuracy: 0.7454 - val_loss: 0.5709 - val_accuracy: 0.7567\n",
      "Epoch 63/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6157 - accuracy: 0.7480 - val_loss: 0.5695 - val_accuracy: 0.7609\n",
      "Epoch 64/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6213 - accuracy: 0.7471 - val_loss: 0.5700 - val_accuracy: 0.7584\n",
      "Epoch 65/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6210 - accuracy: 0.7462 - val_loss: 0.5700 - val_accuracy: 0.7592\n",
      "Epoch 66/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.6176 - accuracy: 0.7475 - val_loss: 0.5687 - val_accuracy: 0.7621\n",
      "Epoch 67/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6208 - accuracy: 0.7417 - val_loss: 0.5688 - val_accuracy: 0.7615\n",
      "Epoch 68/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6133 - accuracy: 0.7471 - val_loss: 0.5678 - val_accuracy: 0.7573\n",
      "Epoch 69/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.7450 - val_loss: 0.5687 - val_accuracy: 0.7584\n",
      "Epoch 70/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6177 - accuracy: 0.7479 - val_loss: 0.5672 - val_accuracy: 0.7635\n",
      "Epoch 71/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6118 - accuracy: 0.7499 - val_loss: 0.5661 - val_accuracy: 0.7629\n",
      "Epoch 72/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6203 - accuracy: 0.7506 - val_loss: 0.5659 - val_accuracy: 0.7640\n",
      "Epoch 73/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6129 - accuracy: 0.7478 - val_loss: 0.5677 - val_accuracy: 0.7615\n",
      "Epoch 74/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6137 - accuracy: 0.7517 - val_loss: 0.5670 - val_accuracy: 0.7609\n",
      "Epoch 75/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6126 - accuracy: 0.7527 - val_loss: 0.5659 - val_accuracy: 0.7623\n",
      "Epoch 76/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6175 - accuracy: 0.7422 - val_loss: 0.5653 - val_accuracy: 0.7663\n",
      "Epoch 77/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6126 - accuracy: 0.7478 - val_loss: 0.5649 - val_accuracy: 0.7649\n",
      "Epoch 78/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.6130 - accuracy: 0.7519 - val_loss: 0.5652 - val_accuracy: 0.7643\n",
      "Epoch 79/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6082 - accuracy: 0.7475 - val_loss: 0.5650 - val_accuracy: 0.7665\n",
      "Epoch 80/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6146 - accuracy: 0.7480 - val_loss: 0.5622 - val_accuracy: 0.7637\n",
      "Epoch 81/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6123 - accuracy: 0.7486 - val_loss: 0.5627 - val_accuracy: 0.7649\n",
      "Epoch 82/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6084 - accuracy: 0.7510 - val_loss: 0.5639 - val_accuracy: 0.7607\n",
      "Epoch 83/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6103 - accuracy: 0.7480 - val_loss: 0.5633 - val_accuracy: 0.7615\n",
      "Epoch 84/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6083 - accuracy: 0.7507 - val_loss: 0.5618 - val_accuracy: 0.7635\n",
      "Epoch 85/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6075 - accuracy: 0.7546 - val_loss: 0.5619 - val_accuracy: 0.7651\n",
      "Epoch 86/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6129 - accuracy: 0.7520 - val_loss: 0.5623 - val_accuracy: 0.7643\n",
      "Epoch 87/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.6052 - accuracy: 0.7527 - val_loss: 0.5584 - val_accuracy: 0.7671\n",
      "Epoch 88/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.5995 - accuracy: 0.7557 - val_loss: 0.5574 - val_accuracy: 0.7654\n",
      "Epoch 89/100\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.5975 - accuracy: 0.7578 - val_loss: 0.5584 - val_accuracy: 0.7646\n",
      "Epoch 90/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6041 - accuracy: 0.7504 - val_loss: 0.5604 - val_accuracy: 0.7657\n",
      "Epoch 91/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6029 - accuracy: 0.7511 - val_loss: 0.5575 - val_accuracy: 0.7654\n",
      "Epoch 92/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6057 - accuracy: 0.7517 - val_loss: 0.5576 - val_accuracy: 0.7657\n",
      "Epoch 93/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.6024 - accuracy: 0.7553 - val_loss: 0.5557 - val_accuracy: 0.7693\n",
      "Epoch 94/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.5938 - accuracy: 0.7548 - val_loss: 0.5564 - val_accuracy: 0.7696\n",
      "Epoch 95/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.5972 - accuracy: 0.7543 - val_loss: 0.5537 - val_accuracy: 0.7710\n",
      "Epoch 96/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.5984 - accuracy: 0.7561 - val_loss: 0.5566 - val_accuracy: 0.7682\n",
      "Epoch 97/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.5956 - accuracy: 0.7606 - val_loss: 0.5541 - val_accuracy: 0.7685\n",
      "Epoch 98/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.5976 - accuracy: 0.7551 - val_loss: 0.5532 - val_accuracy: 0.7682\n",
      "Epoch 99/100\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.5964 - accuracy: 0.7570 - val_loss: 0.5526 - val_accuracy: 0.7707\n",
      "Epoch 100/100\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.6005 - accuracy: 0.7529 - val_loss: 0.5510 - val_accuracy: 0.7727\n",
      "239/239 [==============================] - 1s 2ms/step\n",
      "DNN Accuracy Score: 0.7534013605442177\n",
      "DNN Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.66      0.75      2255\n",
      "           2       0.67      0.69      0.68      2668\n",
      "           3       0.77      0.89      0.83      2721\n",
      "\n",
      "    accuracy                           0.75      7644\n",
      "   macro avg       0.76      0.75      0.75      7644\n",
      "weighted avg       0.76      0.75      0.75      7644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "    X_treinamento, Y_treinamento,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,  # Usando validação interna\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Fazer previsões\n",
    "Y_pred = model.predict(X_teste)\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# Decodificar os rótulos para os rótulos originais\n",
    "Y_pred_decoded = label_encoder.inverse_transform(Y_pred_classes)\n",
    "Y_teste_decoded = label_encoder.inverse_transform(Y_teste)\n",
    "\n",
    "# Avaliar o modelo\n",
    "accuracy = accuracy_score(Y_teste_decoded, Y_pred_decoded)\n",
    "print(\"DNN Accuracy Score:\", accuracy)\n",
    "print(\"DNN Classification Report:\\n\", classification_report(Y_teste_decoded, Y_pred_decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb01949f-13be-4ee4-a15c-f81ca9769bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 2ms/step - loss: 0.5856 - accuracy: 0.7534\n",
      "Test Accuracy: 75.34%\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o modelo nos dados de teste\n",
    "test_loss, test_accuracy = model.evaluate(X_teste, Y_teste)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "770e32dd-615b-4377-91ee-6b8e4aa6b922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "238/238 [==============================] - 4s 6ms/step - loss: 1.6021 - accuracy: 0.3637 - val_loss: 1.0360 - val_accuracy: 0.4159\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 1.2383 - accuracy: 0.4165 - val_loss: 0.9195 - val_accuracy: 0.5750\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 1.0581 - accuracy: 0.4756 - val_loss: 0.8449 - val_accuracy: 0.6180\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.9569 - accuracy: 0.5227 - val_loss: 0.7866 - val_accuracy: 0.6461\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.8975 - accuracy: 0.5565 - val_loss: 0.7468 - val_accuracy: 0.6705\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.8503 - accuracy: 0.5848 - val_loss: 0.7180 - val_accuracy: 0.6910\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 0.8222 - accuracy: 0.6098 - val_loss: 0.7001 - val_accuracy: 0.6957\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.8061 - accuracy: 0.6224 - val_loss: 0.6857 - val_accuracy: 0.7012\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.7854 - accuracy: 0.6377 - val_loss: 0.6775 - val_accuracy: 0.7115\n",
      "Epoch 10/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.7763 - accuracy: 0.6465 - val_loss: 0.6664 - val_accuracy: 0.7138\n",
      "Epoch 11/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.7638 - accuracy: 0.6492 - val_loss: 0.6554 - val_accuracy: 0.7225\n",
      "Epoch 12/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.7508 - accuracy: 0.6584 - val_loss: 0.6475 - val_accuracy: 0.7278\n",
      "Epoch 13/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.7377 - accuracy: 0.6691 - val_loss: 0.6446 - val_accuracy: 0.7359\n",
      "Epoch 14/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.7414 - accuracy: 0.6643 - val_loss: 0.6386 - val_accuracy: 0.7325\n",
      "Epoch 15/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.7276 - accuracy: 0.6721 - val_loss: 0.6293 - val_accuracy: 0.7383\n",
      "Epoch 16/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.7293 - accuracy: 0.6692 - val_loss: 0.6292 - val_accuracy: 0.7430\n",
      "Epoch 17/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.7215 - accuracy: 0.6794 - val_loss: 0.6237 - val_accuracy: 0.7430\n",
      "Epoch 18/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.7184 - accuracy: 0.6860 - val_loss: 0.6217 - val_accuracy: 0.7409\n",
      "Epoch 19/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.7084 - accuracy: 0.6843 - val_loss: 0.6148 - val_accuracy: 0.7456\n",
      "Epoch 20/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.7007 - accuracy: 0.6933 - val_loss: 0.6086 - val_accuracy: 0.7506\n",
      "Epoch 21/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6980 - accuracy: 0.6931 - val_loss: 0.6080 - val_accuracy: 0.7456\n",
      "Epoch 22/100\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 0.6950 - accuracy: 0.6958 - val_loss: 0.5955 - val_accuracy: 0.7558\n",
      "Epoch 23/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6924 - accuracy: 0.7014 - val_loss: 0.5968 - val_accuracy: 0.7532\n",
      "Epoch 24/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.6963 - val_loss: 0.5936 - val_accuracy: 0.7545\n",
      "Epoch 25/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6807 - accuracy: 0.7012 - val_loss: 0.5910 - val_accuracy: 0.7577\n",
      "Epoch 26/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6807 - accuracy: 0.7037 - val_loss: 0.5816 - val_accuracy: 0.7624\n",
      "Epoch 27/100\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 0.6797 - accuracy: 0.7077 - val_loss: 0.5806 - val_accuracy: 0.7624\n",
      "Epoch 28/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6789 - accuracy: 0.7067 - val_loss: 0.5735 - val_accuracy: 0.7690\n",
      "Epoch 29/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6748 - accuracy: 0.7112 - val_loss: 0.5747 - val_accuracy: 0.7598\n",
      "Epoch 30/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6721 - accuracy: 0.7122 - val_loss: 0.5751 - val_accuracy: 0.7611\n",
      "Epoch 31/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6654 - accuracy: 0.7182 - val_loss: 0.5692 - val_accuracy: 0.7637\n",
      "Epoch 32/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6698 - accuracy: 0.7124 - val_loss: 0.5676 - val_accuracy: 0.7624\n",
      "Epoch 33/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6616 - accuracy: 0.7170 - val_loss: 0.5696 - val_accuracy: 0.7650\n",
      "Epoch 34/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6638 - accuracy: 0.7166 - val_loss: 0.5665 - val_accuracy: 0.7653\n",
      "Epoch 35/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6484 - accuracy: 0.7244 - val_loss: 0.5548 - val_accuracy: 0.7724\n",
      "Epoch 36/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6533 - accuracy: 0.7209 - val_loss: 0.5599 - val_accuracy: 0.7708\n",
      "Epoch 37/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6531 - accuracy: 0.7231 - val_loss: 0.5594 - val_accuracy: 0.7719\n",
      "Epoch 38/100\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 0.6473 - accuracy: 0.7257 - val_loss: 0.5527 - val_accuracy: 0.7729\n",
      "Epoch 39/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6491 - accuracy: 0.7273 - val_loss: 0.5597 - val_accuracy: 0.7732\n",
      "Epoch 40/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6476 - accuracy: 0.7227 - val_loss: 0.5527 - val_accuracy: 0.7789\n",
      "Epoch 41/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6479 - accuracy: 0.7231 - val_loss: 0.5552 - val_accuracy: 0.7732\n",
      "Epoch 42/100\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 0.6407 - accuracy: 0.7312 - val_loss: 0.5473 - val_accuracy: 0.7805\n",
      "Epoch 43/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6432 - accuracy: 0.7293 - val_loss: 0.5498 - val_accuracy: 0.7753\n",
      "Epoch 44/100\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 0.6359 - accuracy: 0.7276 - val_loss: 0.5519 - val_accuracy: 0.7724\n",
      "Epoch 45/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6407 - accuracy: 0.7281 - val_loss: 0.5484 - val_accuracy: 0.7787\n",
      "Epoch 46/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6385 - accuracy: 0.7340 - val_loss: 0.5454 - val_accuracy: 0.7845\n",
      "Epoch 47/100\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 0.6393 - accuracy: 0.7314 - val_loss: 0.5435 - val_accuracy: 0.7800\n",
      "Epoch 48/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6355 - accuracy: 0.7348 - val_loss: 0.5440 - val_accuracy: 0.7821\n",
      "Epoch 49/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6350 - accuracy: 0.7321 - val_loss: 0.5451 - val_accuracy: 0.7813\n",
      "Epoch 50/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6339 - accuracy: 0.7352 - val_loss: 0.5490 - val_accuracy: 0.7797\n",
      "Epoch 51/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6339 - accuracy: 0.7334 - val_loss: 0.5449 - val_accuracy: 0.7774\n",
      "Epoch 52/100\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 0.6371 - accuracy: 0.7310 - val_loss: 0.5386 - val_accuracy: 0.7837\n",
      "Epoch 53/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6321 - accuracy: 0.7361 - val_loss: 0.5425 - val_accuracy: 0.7826\n",
      "Epoch 54/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6303 - accuracy: 0.7338 - val_loss: 0.5414 - val_accuracy: 0.7831\n",
      "Epoch 55/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6309 - accuracy: 0.7394 - val_loss: 0.5374 - val_accuracy: 0.7850\n",
      "Epoch 56/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6302 - accuracy: 0.7384 - val_loss: 0.5443 - val_accuracy: 0.7787\n",
      "Epoch 57/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6296 - accuracy: 0.7331 - val_loss: 0.5414 - val_accuracy: 0.7787\n",
      "Epoch 58/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6315 - accuracy: 0.7369 - val_loss: 0.5415 - val_accuracy: 0.7763\n",
      "Epoch 59/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6240 - accuracy: 0.7363 - val_loss: 0.5405 - val_accuracy: 0.7774\n",
      "Epoch 60/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6259 - accuracy: 0.7402 - val_loss: 0.5427 - val_accuracy: 0.7768\n",
      "Epoch 61/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6215 - accuracy: 0.7434 - val_loss: 0.5376 - val_accuracy: 0.7800\n",
      "Epoch 62/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6298 - accuracy: 0.7411 - val_loss: 0.5354 - val_accuracy: 0.7797\n",
      "Epoch 63/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6254 - accuracy: 0.7396 - val_loss: 0.5344 - val_accuracy: 0.7771\n",
      "Epoch 64/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6144 - accuracy: 0.7463 - val_loss: 0.5336 - val_accuracy: 0.7779\n",
      "Epoch 65/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6183 - accuracy: 0.7420 - val_loss: 0.5367 - val_accuracy: 0.7766\n",
      "Epoch 66/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6173 - accuracy: 0.7439 - val_loss: 0.5298 - val_accuracy: 0.7813\n",
      "Epoch 67/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6153 - accuracy: 0.7480 - val_loss: 0.5300 - val_accuracy: 0.7845\n",
      "Epoch 68/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6187 - accuracy: 0.7465 - val_loss: 0.5287 - val_accuracy: 0.7845\n",
      "Epoch 69/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6237 - accuracy: 0.7374 - val_loss: 0.5349 - val_accuracy: 0.7805\n",
      "Epoch 70/100\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 0.6146 - accuracy: 0.7430 - val_loss: 0.5347 - val_accuracy: 0.7795\n",
      "Epoch 71/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.7383 - val_loss: 0.5339 - val_accuracy: 0.7808\n",
      "Epoch 72/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6161 - accuracy: 0.7444 - val_loss: 0.5379 - val_accuracy: 0.7787\n",
      "Epoch 73/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6122 - accuracy: 0.7486 - val_loss: 0.5365 - val_accuracy: 0.7826\n",
      "Epoch 74/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6163 - accuracy: 0.7450 - val_loss: 0.5385 - val_accuracy: 0.7771\n",
      "Epoch 75/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6180 - accuracy: 0.7462 - val_loss: 0.5312 - val_accuracy: 0.7800\n",
      "Epoch 76/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6097 - accuracy: 0.7500 - val_loss: 0.5281 - val_accuracy: 0.7850\n",
      "Epoch 77/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6160 - accuracy: 0.7463 - val_loss: 0.5333 - val_accuracy: 0.7821\n",
      "Epoch 78/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6108 - accuracy: 0.7436 - val_loss: 0.5320 - val_accuracy: 0.7821\n",
      "Epoch 79/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6132 - accuracy: 0.7458 - val_loss: 0.5261 - val_accuracy: 0.7876\n",
      "Epoch 80/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6089 - accuracy: 0.7492 - val_loss: 0.5265 - val_accuracy: 0.7821\n",
      "Epoch 81/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6084 - accuracy: 0.7455 - val_loss: 0.5267 - val_accuracy: 0.7824\n",
      "Epoch 82/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6040 - accuracy: 0.7505 - val_loss: 0.5256 - val_accuracy: 0.7771\n",
      "Epoch 83/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6006 - accuracy: 0.7511 - val_loss: 0.5269 - val_accuracy: 0.7784\n",
      "Epoch 84/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.5994 - accuracy: 0.7572 - val_loss: 0.5261 - val_accuracy: 0.7797\n",
      "Epoch 85/100\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 0.6050 - accuracy: 0.7543 - val_loss: 0.5238 - val_accuracy: 0.7803\n",
      "Epoch 86/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6088 - accuracy: 0.7481 - val_loss: 0.5245 - val_accuracy: 0.7782\n",
      "Epoch 87/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6026 - accuracy: 0.7516 - val_loss: 0.5304 - val_accuracy: 0.7761\n",
      "Epoch 88/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5978 - accuracy: 0.7557 - val_loss: 0.5275 - val_accuracy: 0.7824\n",
      "Epoch 89/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.5996 - accuracy: 0.7539 - val_loss: 0.5180 - val_accuracy: 0.7876\n",
      "Epoch 90/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.5916 - accuracy: 0.7592 - val_loss: 0.5244 - val_accuracy: 0.7831\n",
      "Epoch 91/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.5960 - accuracy: 0.7563 - val_loss: 0.5216 - val_accuracy: 0.7797\n",
      "Epoch 92/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.5999 - accuracy: 0.7549 - val_loss: 0.5209 - val_accuracy: 0.7829\n",
      "Epoch 93/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.5939 - accuracy: 0.7507 - val_loss: 0.5241 - val_accuracy: 0.7818\n",
      "Epoch 94/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5983 - accuracy: 0.7556 - val_loss: 0.5187 - val_accuracy: 0.7884\n",
      "Epoch 95/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5977 - accuracy: 0.7520 - val_loss: 0.5198 - val_accuracy: 0.7829\n",
      "Epoch 96/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6021 - accuracy: 0.7539 - val_loss: 0.5215 - val_accuracy: 0.7855\n",
      "Epoch 97/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5971 - accuracy: 0.7538 - val_loss: 0.5185 - val_accuracy: 0.7876\n",
      "Epoch 98/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5971 - accuracy: 0.7550 - val_loss: 0.5180 - val_accuracy: 0.7902\n",
      "Epoch 99/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.5928 - accuracy: 0.7579 - val_loss: 0.5213 - val_accuracy: 0.7847\n",
      "Epoch 100/100\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5939 - accuracy: 0.7593 - val_loss: 0.5159 - val_accuracy: 0.7884\n",
      "239/239 [==============================] - 1s 2ms/step\n",
      "DNN Accuracy Score: 0.7613814756671899\n",
      "KNN Accuracy Score: 0.6991104133961277\n",
      "DNN Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76      2255\n",
      "           1       0.68      0.70      0.69      2668\n",
      "           2       0.79      0.88      0.83      2721\n",
      "\n",
      "    accuracy                           0.76      7644\n",
      "   macro avg       0.77      0.76      0.76      7644\n",
      "weighted avg       0.77      0.76      0.76      7644\n",
      "\n",
      "KNN Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71      2255\n",
      "           1       0.62      0.62      0.62      2668\n",
      "           2       0.78      0.76      0.77      2721\n",
      "\n",
      "    accuracy                           0.70      7644\n",
      "   macro avg       0.70      0.70      0.70      7644\n",
      "weighted avg       0.70      0.70      0.70      7644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Calcular pesos das classes\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(Y_encoded), y=Y_encoded)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Aplicar SMOTE para reamostragem\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, Y_resampled = smote.fit_resample(X_treinamento, Y_treinamento)\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_resampled = scaler.fit_transform(X_resampled)\n",
    "X_teste = scaler.transform(X_teste)\n",
    "\n",
    "# Construir o modelo de Redes Neurais Profundas\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(X_resampled.shape[1],), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "num_classes = len(np.unique(Y_encoded))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "    X_resampled, Y_resampled,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "# Obter as previsões do modelo de rede neural\n",
    "Y_pred_nn = model.predict(X_teste)\n",
    "Y_pred_nn_classes = np.argmax(Y_pred_nn, axis=1)\n",
    "\n",
    "# Treinar o modelo KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # Ajustar o número de vizinhos conforme necessário\n",
    "knn.fit(X_resampled, Y_resampled)\n",
    "\n",
    "# Obter previsões do modelo KNN\n",
    "Y_pred_knn = knn.predict(X_teste)\n",
    "\n",
    "# Comparar o desempenho dos modelos\n",
    "accuracy_nn = accuracy_score(Y_teste, Y_pred_nn_classes)\n",
    "accuracy_knn = accuracy_score(Y_teste, Y_pred_knn)\n",
    "\n",
    "print(\"DNN Accuracy Score:\", accuracy_nn)\n",
    "print(\"KNN Accuracy Score:\", accuracy_knn)\n",
    "\n",
    "print(\"DNN Classification Report:\\n\", classification_report(Y_teste, Y_pred_nn_classes))\n",
    "print(\"KNN Classification Report:\\n\", classification_report(Y_teste, Y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e92e4c1-4ffd-4985-8975-83ed0b9cb5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 1ms/step\n",
      "Combined Model Accuracy Score: 0.7579801151229723\n",
      "Combined Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      2255\n",
      "           1       0.68      0.69      0.69      2668\n",
      "           2       0.79      0.85      0.82      2721\n",
      "\n",
      "    accuracy                           0.76      7644\n",
      "   macro avg       0.76      0.76      0.76      7644\n",
      "weighted avg       0.76      0.76      0.76      7644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Assumindo que já temos o KNN e DNN treinados\n",
    "\n",
    "# Fazer previsões com o KNN\n",
    "knn_prob = knn.predict_proba(X_teste)\n",
    "\n",
    "# Fazer previsões com o DNN\n",
    "dnn_prob = model.predict(X_teste)\n",
    "\n",
    "# Combinar as previsões usando uma média ponderada (ajuste os pesos conforme necessário)\n",
    "combined_prob = (0.5 * knn_prob) + (0.5 * dnn_prob)\n",
    "\n",
    "# Obter previsões finais\n",
    "Y_pred_combined = np.argmax(combined_prob, axis=1)\n",
    "\n",
    "# Avaliar o modelo combinado\n",
    "print(\"Combined Model Accuracy Score:\", accuracy_score(Y_teste, Y_pred_combined))\n",
    "print(\"Combined Model Classification Report:\\n\", classification_report(Y_teste, Y_pred_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcfc70cd-b9c2-4637-a2de-25d57c91075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 2ms/step\n",
      "F1-Score: 0.7675\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.78      2255\n",
      "           1       0.69      0.70      0.70      2668\n",
      "           2       0.82      0.84      0.83      2721\n",
      "\n",
      "    accuracy                           0.77      7644\n",
      "   macro avg       0.77      0.77      0.77      7644\n",
      "weighted avg       0.77      0.77      0.77      7644\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Previsões no conjunto de teste\n",
    "y_pred = model.predict(X_teste)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Converter probabilidades para classes\n",
    "\n",
    "# Calcular o F1-Score\n",
    "f1 = f1_score(Y_teste, y_pred_classes, average='weighted')\n",
    "print(f'F1-Score: {f1:.4f}')\n",
    "\n",
    "# Relatório de classificação detalhado\n",
    "report = classification_report(Y_teste, y_pred_classes, target_names=[str(i) for i in np.unique(Y_encoded)])\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Matriz de confusão\n",
    "conf_matrix = confusion_matrix(Y_teste, y_pred_classes)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[str(i) for i in np.unique(Y_encoded)],\n",
    "            yticklabels=[str(i) for i in np.unique(Y_encoded)])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1f16c3f-cb57-456c-9c7c-d4e3d3f4cffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo TensorFlow salvo no caminho: saved_model\n",
      "Modelo salvo como model.pkl\n",
      "Modelo salvo como model.joblib\n",
      "model.pkl foi carregado para o bucket s3sagemakermo com o nome model.pkl\n",
      "model.joblib foi carregado para o bucket s3sagemakermo com o nome model.joblib\n",
      "saved_model/saved_model.pb foi carregado para o bucket s3sagemakermo com o nome saved_model/saved_model.pb\n",
      "saved_model/fingerprint.pb foi carregado para o bucket s3sagemakermo com o nome saved_model/fingerprint.pb\n",
      "saved_model/keras_metadata.pb foi carregado para o bucket s3sagemakermo com o nome saved_model/keras_metadata.pb\n",
      "saved_model/variables/variables.data-00000-of-00001 foi carregado para o bucket s3sagemakermo com o nome saved_model/variables.data-00000-of-00001\n",
      "saved_model/variables/variables.index foi carregado para o bucket s3sagemakermo com o nome saved_model/variables.index\n",
      "Todos os arquivos foram carregados para o S3 com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.model import Model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Definindo o nome do bucket e o caminho do modelo\n",
    "bucket_name = \"s3sagemakermo\"\n",
    "model_path = \"model\"\n",
    "saved_model_path = \"saved_model\"\n",
    "\n",
    "# Salvar o modelo TensorFlow\n",
    "model.save(saved_model_path)\n",
    "print(f\"Modelo TensorFlow salvo no caminho: {saved_model_path}\")\n",
    "\n",
    "# Salvar o modelo em formato .pkl\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"Modelo salvo como model.pkl\")\n",
    "\n",
    "# Salvar o modelo em formato .joblib\n",
    "joblib.dump(model, 'model.joblib')\n",
    "print(\"Modelo salvo como model.joblib\")\n",
    "\n",
    "# Configurar boto3 para o upload no S3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Fazer o upload do modelo para o bucket S3\n",
    "def upload_to_s3(file_name, bucket, object_name=None):\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "    s3.upload_file(file_name, bucket, object_name)\n",
    "    print(f\"{file_name} foi carregado para o bucket {bucket} com o nome {object_name}\")\n",
    "\n",
    "# Carregar os arquivos para o bucket S3\n",
    "upload_to_s3('model.pkl', bucket_name)\n",
    "upload_to_s3('model.joblib', bucket_name)\n",
    "\n",
    "# Salvar o modelo TensorFlow no S3\n",
    "def upload_directory_to_s3(local_directory, bucket_name, s3_directory):\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for file in files:\n",
    "            local_file = os.path.join(root, file)\n",
    "            s3_file = os.path.join(s3_directory, file)\n",
    "            s3.upload_file(local_file, bucket_name, s3_file)\n",
    "            print(f\"{local_file} foi carregado para o bucket {bucket_name} com o nome {s3_file}\")\n",
    "\n",
    "upload_directory_to_s3(saved_model_path, bucket_name, 'saved_model')\n",
    "\n",
    "print(\"Todos os arquivos foram carregados para o S3 com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ae380-c3f6-4897-916c-32f6ab1af802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
