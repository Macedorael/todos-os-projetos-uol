{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import xgboost as xgb  # Adicione esta linha para importar XGBoost\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Carregar o dataset\n",
        "base_hotel = pd.read_csv(r'/content/Hotel Reservations.csv')\n",
        "\n",
        "# Classificação de preço\n",
        "def classify_price(price):\n",
        "    if price <= 85:\n",
        "        return 1  # Mantendo o formato 1, 2, 3\n",
        "    elif 85 < price < 115:\n",
        "        return 2  # Mantendo o formato 1, 2, 3\n",
        "    else:\n",
        "        return 3  # Mantendo o formato 1, 2, 3\n",
        "\n",
        "# Criar a coluna de label 'label_avg_price_per_room'\n",
        "base_hotel['label_avg_price_per_room'] = base_hotel['avg_price_per_room'].apply(classify_price)\n",
        "base_hotel = base_hotel.drop(columns=['avg_price_per_room'])\n",
        "\n",
        "# Reorganizar as colunas\n",
        "colunas = []\n",
        "colunas.append('label_avg_price_per_room')\n",
        "for i in range(len(base_hotel.columns[:-1])):\n",
        "    print(base_hotel.columns[i])\n",
        "    colunas.append(base_hotel.columns[i])\n",
        "\n",
        "base_hotel = base_hotel[colunas]\n",
        "\n",
        "# Lista de colunas a serem removidas\n",
        "colunas_para_remover = ['Booking_ID', 'arrival_date', 'market_segment_type',\n",
        "                         'repeated_guest', 'no_of_previous_cancellations',\n",
        "                         'no_of_previous_bookings_not_canceled', 'booking_status']\n",
        "\n",
        "# Filtrar e remover as colunas existentes\n",
        "colunas_existentes = [col for col in colunas_para_remover if col in base_hotel.columns]\n",
        "base_hotel = base_hotel.drop(columns=colunas_existentes, axis=1).copy()\n",
        "\n",
        "# Aplicando One-Hot Encoding\n",
        "base_hotel = pd.get_dummies(base_hotel, prefix=['type_of_meal_plan', 'required_car_parking_space',\n",
        "                                                'room_type_reserved', 'arrival_year', 'arrival_month',\n",
        "                                                'no_of_special_requests'],\n",
        "                             columns=['type_of_meal_plan', 'required_car_parking_space',\n",
        "                                      'room_type_reserved', 'arrival_year', 'arrival_month',\n",
        "                                      'no_of_special_requests'])\n",
        "\n",
        "# Definindo X e y\n",
        "X = base_hotel.iloc[:, 1:].values\n",
        "X = np.array(X).astype('float32')\n",
        "y = base_hotel.iloc[:, 0].values\n",
        "\n",
        "# Codificar os rótulos para começarem de 0\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Dividir o conjunto de dados em treinamento e teste\n",
        "X_treinamento, X_teste, Y_treinamento, Y_teste = train_test_split(X, y_encoded, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "Oj4rfP6bEQXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jHmchqoD4IC"
      },
      "outputs": [],
      "source": [
        "# Extrair as features (X) e o target (Y)\n",
        "X = base_hotel.iloc[:, 1:].values  # Seleciona todas as colunas exceto a primeira para X\n",
        "Y = base_hotel.iloc[:, 0].values   # Seleciona a primeira coluna (label_avg_price_per_room) para Y\n",
        "\n",
        "# Codificação das variáveis categóricas\n",
        "label_encoders = {}\n",
        "for i, column in enumerate(base_hotel.columns[1:], start=1):\n",
        "    if base_hotel[column].dtype == 'object':\n",
        "        le = LabelEncoder()\n",
        "        X[:, i-1] = le.fit_transform(X[:, i-1])\n",
        "        label_encoders[column] = le\n",
        "\n",
        "# Converte X para float32\n",
        "X = np.array(X).astype('float32')\n",
        "\n",
        "# Codifique os rótulos para inteiros consecutivos, começando de 0\n",
        "label_encoder = LabelEncoder()\n",
        "Y_encoded = label_encoder.fit_transform(Y)\n",
        "\n",
        "# Dividir o conjunto de dados em treinamento e teste\n",
        "X_treinamento, X_teste, Y_treinamento, Y_teste = train_test_split(X, Y_encoded, test_size=0.3, random_state=0)\n",
        "\n",
        "# Configuração dos hiperparâmetros para RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'n_estimators': [50, 100, 200],  # Número de árvores\n",
        "    'max_depth': [10, 15],  # Profundidade máxima da árvore\n",
        "    'learning_rate': [0.05, 0.1],  # Taxa de aprendizado\n",
        "    'subsample': [0.9, 1.0],  # Proporção de amostras usadas para ajustar cada árvore\n",
        "    'colsample_bytree': [0.8, 0.9],  # Proporção de colunas usadas para ajustar cada árvore\n",
        "    'gamma': [0, 0.2],  # Regularização por complexidade de modelo\n",
        "    'min_child_weight': [1, 3],  # Peso mínimo da folha\n",
        "    'reg_alpha': [0, 0.1],  # Regularização L1\n",
        "    'reg_lambda': [1, 1.5]  # Regularização L2\n",
        "}\n",
        "\n",
        "# Inicializar o classificador XGBoost\n",
        "model_xgb = xgb.XGBClassifier(\n",
        "    eval_metric='mlogloss',  # Métrica para problemas de classificação multiclasse\n",
        "    num_class=len(np.unique(Y_encoded))  # Número de classes\n",
        ")\n",
        "\n",
        "# Inicializar o RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model_xgb,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=100,  # Número de combinações aleatórias a serem testadas\n",
        "    scoring='accuracy',\n",
        "    cv=3,  # Número de folds para cross-validation\n",
        "    n_jobs=-1,  # Utiliza todos os núcleos do processador\n",
        "    verbose=2,  # Mostra detalhes sobre o progresso\n",
        "    random_state=0  # Para reprodutibilidade\n",
        ")\n",
        "\n",
        "# Treinar o RandomizedSearchCV\n",
        "random_search.fit(X_treinamento, Y_treinamento)\n",
        "\n",
        "# Melhor combinação de hiperparâmetros\n",
        "print(\"Melhores hiperparâmetros encontrados:\\n\", random_search.best_params_)\n",
        "\n",
        "# Melhor modelo encontrado\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Fazer previsões\n",
        "Y_pred_xgb_encoded = best_model.predict(X_teste)\n",
        "\n",
        "# Decodificar as previsões de volta para os rótulos originais\n",
        "Y_pred_xgb = label_encoder.inverse_transform(Y_pred_xgb_encoded)\n",
        "\n",
        "# Decodificar os rótulos de teste para os rótulos originais\n",
        "Y_teste_decoded = label_encoder.inverse_transform(Y_teste)\n",
        "\n",
        "# Avaliar o modelo\n",
        "print(\"XGBoost Accuracy Score:\", accuracy_score(Y_teste_decoded, Y_pred_xgb))\n",
        "print(\"XGBoost Classification Report:\\n\", classification_report(Y_teste_decoded, Y_pred_xgb))\n",
        "\n",
        "# Verifique as classes únicas no conjunto de teste e previsões\n",
        "print(\"Classes únicas no conjunto de teste:\", np.unique(Y_teste_decoded))\n",
        "print(\"Classes únicas nas previsões:\", np.unique(Y_pred_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import xgboost as xgb  # Adicione esta linha para importar XGBoost\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Carregar o dataset\n",
        "base_hotel = pd.read_csv(r'/content/Hotel Reservations.csv')\n",
        "\n",
        "# Classificação de preço\n",
        "def classify_price(price):\n",
        "    if price <= 85:\n",
        "        return 1  # Mantendo o formato 1, 2, 3\n",
        "    elif 85 < price < 115:\n",
        "        return 2  # Mantendo o formato 1, 2, 3\n",
        "    else:\n",
        "        return 3  # Mantendo o formato 1, 2, 3\n",
        "\n",
        "# Criar a coluna de label 'label_avg_price_per_room'\n",
        "base_hotel['label_avg_price_per_room'] = base_hotel['avg_price_per_room'].apply(classify_price)\n",
        "base_hotel = base_hotel.drop(columns=['avg_price_per_room'])\n",
        "\n",
        "# Reorganizar as colunas\n",
        "colunas = []\n",
        "colunas.append('label_avg_price_per_room')\n",
        "for i in range(len(base_hotel.columns[:-1])):\n",
        "    colunas.append(base_hotel.columns[i])\n",
        "\n",
        "base_hotel = base_hotel[colunas]\n",
        "\n",
        "# Lista de colunas a serem removidas\n",
        "colunas_para_remover = ['Booking_ID', 'arrival_date', 'market_segment_type',\n",
        "                         'repeated_guest', 'no_of_previous_cancellations',\n",
        "                         'no_of_previous_bookings_not_canceled', 'booking_status']\n",
        "\n",
        "# Filtrar e remover as colunas existentes\n",
        "colunas_existentes = [col for col in colunas_para_remover if col in base_hotel.columns]\n",
        "base_hotel = base_hotel.drop(columns=colunas_existentes, axis=1).copy()\n",
        "\n",
        "# Aplicando One-Hot Encoding\n",
        "base_hotel = pd.get_dummies(base_hotel, prefix=['type_of_meal_plan', 'required_car_parking_space',\n",
        "                                                'room_type_reserved', 'arrival_year', 'arrival_month',\n",
        "                                                'no_of_special_requests'],\n",
        "                             columns=['type_of_meal_plan', 'required_car_parking_space',\n",
        "                                      'room_type_reserved', 'arrival_year', 'arrival_month',\n",
        "                                      'no_of_special_requests'])\n",
        "\n",
        "# Definindo X e y\n",
        "X = base_hotel.iloc[:, 1:].values\n",
        "X = np.array(X).astype('float32')\n",
        "y = base_hotel.iloc[:, 0].values\n",
        "\n",
        "# Codificar os rótulos para começarem de 0\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Dividir o conjunto de dados em treinamento e teste\n",
        "X_treinamento, X_teste, Y_treinamento, Y_teste = train_test_split(X, y_encoded, test_size=0.3, random_state=0)\n",
        "\n",
        "# Configuração dos hiperparâmetros para RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'n_estimators': [50, 100, 200],  # Número de árvores\n",
        "    'max_depth': [10, 15],  # Profundidade máxima da árvore\n",
        "    'learning_rate': [0.05, 0.1],  # Taxa de aprendizado\n",
        "    'subsample': [0.9, 1.0],  # Proporção de amostras usadas para ajustar cada árvore\n",
        "    'colsample_bytree': [0.8, 0.9],  # Proporção de colunas usadas para ajustar cada árvore\n",
        "    'gamma': [0, 0.2],  # Regularização por complexidade de modelo\n",
        "    'min_child_weight': [1, 3],  # Peso mínimo da folha\n",
        "    'reg_alpha': [0, 0.1],  # Regularização L1\n",
        "    'reg_lambda': [1, 1.5]  # Regularização L2\n",
        "}\n",
        "\n",
        "# Inicializar o classificador XGBoost\n",
        "model_xgb = xgb.XGBClassifier(\n",
        "    eval_metric='mlogloss',  # Métrica para problemas de classificação multiclasse\n",
        "    num_class=len(np.unique(y_encoded))  # Número de classes\n",
        ")\n",
        "\n",
        "# Inicializar o RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model_xgb,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=100,  # Número de combinações aleatórias a serem testadas\n",
        "    scoring='accuracy',\n",
        "    cv=3,  # Número de folds para cross-validation\n",
        "    n_jobs=-1,  # Utiliza todos os núcleos do processador\n",
        "    verbose=2,  # Mostra detalhes sobre o progresso\n",
        "    random_state=0  # Para reprodutibilidade\n",
        ")\n",
        "\n",
        "# Treinar o RandomizedSearchCV\n",
        "random_search.fit(X_treinamento, Y_treinamento)\n",
        "\n",
        "# Melhor combinação de hiperparâmetros\n",
        "print(\"Melhores hiperparâmetros encontrados:\\n\", random_search.best_params_)\n",
        "\n",
        "# Melhor modelo encontrado\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Fazer previsões\n",
        "Y_pred_xgb_encoded = best_model.predict(X_teste)\n",
        "\n",
        "# Decodificar as previsões de volta para os rótulos originais\n",
        "Y_pred_xgb = label_encoder.inverse_transform(Y_pred_xgb_encoded)\n",
        "\n",
        "# Decodificar os rótulos de teste para os rótulos originais\n",
        "Y_teste_decoded = label_encoder.inverse_transform(Y_teste)\n",
        "\n",
        "# Avaliar o modelo\n",
        "print(\"XGBoost Accuracy Score:\", accuracy_score(Y_teste_decoded, Y_pred_xgb))\n",
        "print(\"XGBoost Classification Report:\\n\", classification_report(Y_teste_decoded, Y_pred_xgb))\n",
        "\n",
        "# Verifique as classes únicas no conjunto de teste e previsões\n",
        "print(\"Classes únicas no conjunto de teste:\", np.unique(Y_teste_decoded))\n",
        "print(\"Classes únicas nas previsões:\", np.unique(Y_pred_xgb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "collapsed": true,
        "id": "b1Phj5YKEyj8",
        "outputId": "af15d236-b275-4806-a684-a177bdc54d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4f804f6e6b8a>\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Treinar o RandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_treinamento\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Melhor combinação de hiperparâmetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1807\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1809\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1810\u001b[0m             ParameterSampler(\n\u001b[1;32m   1811\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    843\u001b[0m                     )\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    846\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         )\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Carregar o dataset\n",
        "base_hotel = pd.read_csv(r'/content/Hotel Reservations.csv')\n",
        "\n",
        "# Função para classificar o preço\n",
        "def classify_price(price):\n",
        "    if price <= 85:\n",
        "        return 1\n",
        "\n",
        "    elif price > 85 and price < 115:\n",
        "        return 2\n",
        "    else:\n",
        "        return 3\n",
        "\n",
        "# Criar a coluna de label 'label_avg_price_per_room'\n",
        "base_hotel['label_avg_price_per_room'] = base_hotel['avg_price_per_room'].apply(classify_price)\n",
        "base_hotel = base_hotel.drop(columns=['avg_price_per_room'])\n",
        "\n",
        "# Reorganizar as colunas\n",
        "colunas = ['label_avg_price_per_room'] + [col for col in base_hotel.columns if col != 'label_avg_price_per_room']\n",
        "base_hotel = base_hotel[colunas]\n",
        "\n",
        "# Lista de colunas a serem removidas\n",
        "colunas_para_remover = ['Booking_ID', 'arrival_date', 'market_segment_type',\n",
        "                         'repeated_guest', 'no_of_previous_cancellations',\n",
        "                         'no_of_previous_bookings_not_canceled', 'booking_status']\n",
        "\n",
        "# Filtrar e remover as colunas existentes\n",
        "colunas_existentes = [col for col in colunas_para_remover if col in base_hotel.columns]\n",
        "base_hotel = base_hotel.drop(columns=colunas_existentes, axis=1).copy()\n",
        "\n",
        "# Aplicando One-Hot Encoding\n",
        "base_hotel = pd.get_dummies(base_hotel, prefix=['type_of_meal_plan', 'required_car_parking_space',\n",
        "                                                'room_type_reserved', 'arrival_year', 'arrival_month',\n",
        "                                                'no_of_special_requests'],\n",
        "                             columns=['type_of_meal_plan', 'required_car_parking_space',\n",
        "                                      'room_type_reserved', 'arrival_year', 'arrival_month',\n",
        "                                      'no_of_special_requests'])\n",
        "\n",
        "# Definindo X e y\n",
        "X = base_hotel.drop(columns=['label_avg_price_per_room']).values.astype('float32')\n",
        "y = base_hotel['label_avg_price_per_room'].values\n",
        "\n",
        "# Codificar os rótulos para começarem de 0\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Dividir o conjunto de dados em treinamento e teste\n",
        "X_treinamento, X_teste, Y_treinamento, Y_teste = train_test_split(X, y_encoded, test_size=0.3, random_state=0)\n",
        "\n",
        "# Configuração dos hiperparâmetros para RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 15],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'subsample': [0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9],\n",
        "    'gamma': [0, 0.2],\n",
        "    'min_child_weight': [1, 3],\n",
        "    'reg_alpha': [0, 0.1],\n",
        "    'reg_lambda': [1, 1.5]\n",
        "}\n",
        "\n",
        "# Inicializar o classificador XGBoost\n",
        "model_xgb = xgb.XGBClassifier(\n",
        "    eval_metric='mlogloss',\n",
        "    num_class=len(np.unique(y_encoded))\n",
        ")\n",
        "\n",
        "# Inicializar o RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model_xgb,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=20,  # Reduzindo o número de combinações para acelerar\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "# Treinar o RandomizedSearchCV\n",
        "random_search.fit(X_treinamento, Y_treinamento)\n",
        "\n",
        "# Melhor combinação de hiperparâmetros\n",
        "print(\"Melhores hiperparâmetros encontrados:\\n\", random_search.best_params_)\n",
        "\n",
        "# Melhor modelo encontrado\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Fazer previsões\n",
        "Y_pred_xgb_encoded = best_model.predict(X_teste)\n",
        "\n",
        "# Decodificar as previsões de volta para os rótulos originais\n",
        "Y_pred_xgb = label_encoder.inverse_transform(Y_pred_xgb_encoded)\n",
        "\n",
        "# Decodificar os rótulos de teste para os rótulos originais\n",
        "Y_teste_decoded = label_encoder.inverse_transform(Y_teste)\n",
        "\n",
        "# Avaliar o modelo\n",
        "print(\"XGBoost Accuracy Score:\", accuracy_score(Y_teste_decoded, Y_pred_xgb))\n",
        "print(\"XGBoost Classification Report:\\n\", classification_report(Y_teste_decoded, Y_pred_xgb))\n",
        "\n",
        "# Verifique as classes únicas no conjunto de teste e previsões\n",
        "print(\"Classes únicas no conjunto de teste:\", np.unique(Y_teste_decoded))\n",
        "print(\"Classes únicas nas previsões:\", np.unique(Y_pred_xgb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCW1sJ8TGYvh",
        "outputId": "ce47c4d8-544f-4fce-c547-da79f0cb4d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "Melhores hiperparâmetros encontrados:\n",
            " {'subsample': 0.9, 'reg_lambda': 1.5, 'reg_alpha': 0, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 15, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.9}\n",
            "XGBoost Accuracy Score: 0.7953689240099238\n",
            "XGBoost Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      0.79      0.80      3258\n",
            "           2       0.76      0.76      0.76      4006\n",
            "           3       0.83      0.84      0.83      3619\n",
            "\n",
            "    accuracy                           0.80     10883\n",
            "   macro avg       0.80      0.80      0.80     10883\n",
            "weighted avg       0.80      0.80      0.80     10883\n",
            "\n",
            "Classes únicas no conjunto de teste: [1 2 3]\n",
            "Classes únicas nas previsões: [1 2 3]\n"
          ]
        }
      ]
    }
  ]
}