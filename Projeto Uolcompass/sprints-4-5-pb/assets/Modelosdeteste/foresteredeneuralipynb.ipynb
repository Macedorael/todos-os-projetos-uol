{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzBRSCdQVgOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79a94106-ee30-4dce-ec1e-2b3c96a9cc46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "XGBoost Accuracy Score: 0.7953689240099238\n",
            "XGBoost Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      0.79      0.80      3258\n",
            "           2       0.76      0.76      0.76      4006\n",
            "           3       0.83      0.84      0.83      3619\n",
            "\n",
            "    accuracy                           0.80     10883\n",
            "   macro avg       0.80      0.80      0.80     10883\n",
            "weighted avg       0.80      0.80      0.80     10883\n",
            "\n",
            "Random Forest Accuracy Score: 0.7848019847468529\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.79      0.78      0.79      3258\n",
            "           2       0.75      0.75      0.75      4006\n",
            "           3       0.82      0.83      0.82      3619\n",
            "\n",
            "    accuracy                           0.78     10883\n",
            "   macro avg       0.79      0.79      0.79     10883\n",
            "weighted avg       0.78      0.78      0.78     10883\n",
            "\n",
            "MLP Accuracy Score: 0.7059634292015069\n",
            "MLP Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.76      0.66      0.70      3258\n",
            "           2       0.64      0.68      0.66      4006\n",
            "           3       0.74      0.78      0.76      3619\n",
            "\n",
            "    accuracy                           0.71     10883\n",
            "   macro avg       0.71      0.71      0.71     10883\n",
            "weighted avg       0.71      0.71      0.71     10883\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Carregar o dataset\n",
        "base_hotel = pd.read_csv(r'/content/Hotel Reservations.csv')\n",
        "\n",
        "# Classificação de preço\n",
        "def classify_price(price):\n",
        "    if price <= 85:\n",
        "        return 1  # Mantendo o formato 1, 2, 3\n",
        "    elif 85 < price < 115:\n",
        "        return 2  # Mantendo o formato 1, 2, 3\n",
        "    else:\n",
        "        return 3  # Mantendo o formato 1, 2, 3\n",
        "\n",
        "# Criar a coluna de label 'label_avg_price_per_room'\n",
        "base_hotel['label_avg_price_per_room'] = base_hotel['avg_price_per_room'].apply(classify_price)\n",
        "base_hotel = base_hotel.drop(columns=['avg_price_per_room'])\n",
        "\n",
        "# Reorganizar as colunas\n",
        "colunas = ['label_avg_price_per_room'] + list(base_hotel.columns[:-1])\n",
        "base_hotel = base_hotel[colunas]\n",
        "\n",
        "# Lista de colunas a serem removidas\n",
        "colunas_para_remover = ['Booking_ID', 'arrival_date', 'market_segment_type',\n",
        "                         'repeated_guest', 'no_of_previous_cancellations',\n",
        "                         'no_of_previous_bookings_not_canceled', 'booking_status']\n",
        "\n",
        "# Filtrar e remover as colunas existentes\n",
        "colunas_existentes = [col for col in colunas_para_remover if col in base_hotel.columns]\n",
        "base_hotel = base_hotel.drop(columns=colunas_existentes, axis=1).copy()\n",
        "\n",
        "# Aplicando One-Hot Encoding\n",
        "base_hotel = pd.get_dummies(base_hotel, prefix=['type_of_meal_plan', 'required_car_parking_space',\n",
        "                                                'room_type_reserved', 'arrival_year', 'arrival_month',\n",
        "                                                'no_of_special_requests'],\n",
        "                             columns=['type_of_meal_plan', 'required_car_parking_space',\n",
        "                                      'room_type_reserved', 'arrival_year', 'arrival_month',\n",
        "                                      'no_of_special_requests'])\n",
        "\n",
        "# Definindo X e y\n",
        "X = base_hotel.iloc[:, 1:].values\n",
        "X = np.array(X).astype('float32')\n",
        "y = base_hotel.iloc[:, 0].values\n",
        "\n",
        "# Codificar os rótulos para começarem de 0\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Dividir o conjunto de dados em treinamento e teste\n",
        "X_treinamento, X_teste, Y_treinamento, Y_teste = train_test_split(X, y_encoded, test_size=0.3, random_state=0)\n",
        "\n",
        "# Configuração dos hiperparâmetros para RandomizedSearchCV para XGBoost\n",
        "param_distributions_xgb = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 15],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'subsample': [0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9],\n",
        "    'gamma': [0, 0.2],\n",
        "    'min_child_weight': [1, 3],\n",
        "    'reg_alpha': [0, 0.1],\n",
        "    'reg_lambda': [1, 1.5]\n",
        "}\n",
        "\n",
        "# Inicializar o classificador XGBoost\n",
        "model_xgb = xgb.XGBClassifier(\n",
        "    eval_metric='mlogloss',\n",
        "    num_class=len(np.unique(y_encoded))\n",
        ")\n",
        "\n",
        "# Inicializar o RandomizedSearchCV para XGBoost\n",
        "random_search_xgb = RandomizedSearchCV(\n",
        "    estimator=model_xgb,\n",
        "    param_distributions=param_distributions_xgb,\n",
        "    n_iter=20,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "# Treinar o RandomizedSearchCV para XGBoost\n",
        "random_search_xgb.fit(X_treinamento, Y_treinamento)\n",
        "best_model_xgb = random_search_xgb.best_estimator_\n",
        "\n",
        "# Fazer previsões com XGBoost\n",
        "Y_pred_xgb_encoded = best_model_xgb.predict(X_teste)\n",
        "Y_pred_xgb = label_encoder.inverse_transform(Y_pred_xgb_encoded)\n",
        "Y_teste_decoded = label_encoder.inverse_transform(Y_teste)\n",
        "\n",
        "# Avaliar o modelo XGBoost\n",
        "print(\"XGBoost Accuracy Score:\", accuracy_score(Y_teste_decoded, Y_pred_xgb))\n",
        "print(\"XGBoost Classification Report:\\n\", classification_report(Y_teste_decoded, Y_pred_xgb))\n",
        "\n",
        "# Inicializar e treinar o classificador Random Forest\n",
        "model_rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "model_rf.fit(X_treinamento, Y_treinamento)\n",
        "\n",
        "# Fazer previsões com Random Forest\n",
        "Y_pred_rf_encoded = model_rf.predict(X_teste)\n",
        "Y_pred_rf = label_encoder.inverse_transform(Y_pred_rf_encoded)\n",
        "\n",
        "# Avaliar o modelo Random Forest\n",
        "print(\"Random Forest Accuracy Score:\", accuracy_score(Y_teste_decoded, Y_pred_rf))\n",
        "print(\"Random Forest Classification Report:\\n\", classification_report(Y_teste_decoded, Y_pred_rf))\n",
        "\n",
        "# Inicializar e treinar a rede neural MLP\n",
        "model_mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=0)\n",
        "model_mlp.fit(X_treinamento, Y_treinamento)\n",
        "\n",
        "# Fazer previsões com MLP\n",
        "Y_pred_mlp_encoded = model_mlp.predict(X_teste)\n",
        "Y_pred_mlp = label_encoder.inverse_transform(Y_pred_mlp_encoded)\n",
        "\n",
        "# Avaliar o modelo MLP\n",
        "print(\"MLP Accuracy Score:\", accuracy_score(Y_teste_decoded, Y_pred_mlp))\n",
        "print(\"MLP Classification Report:\\n\", classification_report(Y_teste_decoded, Y_pred_mlp))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Carregamento e pré-processamento dos dados\n",
        "#Treinamento e ajuste de hiperparâmetros para Random Forest, MLP e XGBoost\n",
        "# Avaliação dos modelos\n",
        "#Uso de Voting Classifier para combinar os modelos\n",
        "#Validação cruzada"
      ],
      "metadata": {
        "id": "UPCKrQayXxzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Carregar e pré-processar os dados\n",
        "base_hotel = pd.read_csv('/content/Hotel Reservations.csv')\n",
        "\n",
        "# Função para classificar o preço\n",
        "def classify_price(price):\n",
        "    if price <= 85:\n",
        "        return 1\n",
        "\n",
        "    elif price > 85 and price < 115:\n",
        "        return 2\n",
        "    else:\n",
        "        return 3\n",
        "\n",
        "# Criar a coluna de label 'label_avg_price_per_room'\n",
        "base_hotel['label_avg_price_per_room'] = base_hotel['avg_price_per_room'].apply(classify_price)\n",
        "base_hotel = base_hotel.drop(columns=['avg_price_per_room'])\n",
        "\n",
        "# Reorganizar as colunas\n",
        "colunas = ['label_avg_price_per_room'] + list(base_hotel.columns[:-1])\n",
        "base_hotel = base_hotel[colunas]\n",
        "\n",
        "# Lista de colunas a serem removidas\n",
        "colunas_para_remover = ['Booking_ID', 'arrival_date', 'market_segment_type',\n",
        "                         'repeated_guest', 'no_of_previous_cancellations',\n",
        "                         'no_of_previous_bookings_not_canceled', 'booking_status']\n",
        "colunas_existentes = [col for col in colunas_para_remover if col in base_hotel.columns]\n",
        "base_hotel = base_hotel.drop(columns=colunas_existentes, axis=1).copy()\n",
        "\n",
        "# Aplicando One-Hot Encoding\n",
        "base_hotel = pd.get_dummies(base_hotel, prefix=['type_of_meal_plan', 'required_car_parking_space',\n",
        "                                                'room_type_reserved', 'arrival_year', 'arrival_month',\n",
        "                                                'no_of_special_requests'],\n",
        "                             columns=['type_of_meal_plan', 'required_car_parking_space',\n",
        "                                      'room_type_reserved', 'arrival_year', 'arrival_month',\n",
        "                                      'no_of_special_requests'])\n",
        "\n",
        "# Definindo X e y\n",
        "X = base_hotel.iloc[:, 1:].values\n",
        "y = base_hotel.iloc[:, 0].values\n",
        "\n",
        "# Codificar os rótulos para começarem de 0\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Dividir o conjunto de dados em treinamento e teste\n",
        "X_treinamento, X_teste, Y_treinamento, Y_teste = train_test_split(X, y_encoded, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "_wR-2fq4cLiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Configuração reduzida para GridSearchCV para XGBoost\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 150],\n",
        "    'max_depth': [10, 15],\n",
        "    'learning_rate': [0.1],\n",
        "    'subsample': [0.8],\n",
        "    'colsample_bytree': [0.8, 0.9],\n",
        "    'gamma': [0],\n",
        "    'reg_alpha': [0],\n",
        "    'reg_lambda': [1]\n",
        "}\n",
        "\n",
        "model_xgb = XGBClassifier(random_state=0)\n",
        "grid_search_xgb = GridSearchCV(estimator=model_xgb, param_grid=param_grid_xgb, scoring='accuracy', cv=2, n_jobs=-1, verbose=2)\n",
        "grid_search_xgb.fit(X_treinamento, Y_treinamento)\n",
        "best_xgb_model = grid_search_xgb.best_estimator_\n",
        "\n",
        "print(\"Melhores hiperparâmetros para XGBoost:\\n\", grid_search_xgb.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kMvlYilpW-T",
        "outputId": "0649fe21-82d0-4587-ac54-7ac474d95261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "Melhores hiperparâmetros para XGBoost:\n",
            " {'colsample_bytree': 0.9, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configuração para RandomizedSearchCV para Random Forest\n",
        "param_dist_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "model_rf = RandomForestClassifier(random_state=0)\n",
        "random_search_rf = RandomizedSearchCV(estimator=model_rf, param_distributions=param_dist_rf, n_iter=20, scoring='accuracy', cv=3, n_jobs=-1, verbose=2, random_state=0)\n",
        "random_search_rf.fit(X_treinamento, Y_treinamento)\n",
        "best_rf_model = random_search_rf.best_estimator_\n",
        "\n",
        "print(\"Melhores hiperparâmetros para Random Forest:\\n\", random_search_rf.best_params_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3B-jDvacPrk",
        "outputId": "de0afe94-347e-4d71-dc99-694651e760c6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "Melhores hiperparâmetros para Random Forest:\n",
            " {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 20, 'bootstrap': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração reduzida para RandomizedSearchCV para MLP\n",
        "param_dist_mlp = {\n",
        "    'hidden_layer_sizes': [(50,), (100,)],\n",
        "    'activation': ['relu'],\n",
        "    'solver': ['adam'],\n",
        "    'alpha': [0.0001, 0.001],\n",
        "    'learning_rate': ['constant']\n",
        "}\n",
        "\n",
        "model_mlp = MLPClassifier(max_iter=200, random_state=0)  # Reduzido o número de iterações\n",
        "random_search_mlp = RandomizedSearchCV(estimator=model_mlp, param_distributions=param_dist_mlp, n_iter=10, scoring='accuracy', cv=2, n_jobs=-1, verbose=2, random_state=0)\n",
        "random_search_mlp.fit(X_treinamento, Y_treinamento)\n",
        "best_mlp_model = random_search_mlp.best_estimator_\n",
        "\n",
        "print(\"Melhores hiperparâmetros para MLP:\\n\", random_search_mlp.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAoGatv0pf-C",
        "outputId": "87935e7e-4476-45a5-a7dd-658847b055f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores hiperparâmetros para MLP:\n",
            " {'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'alpha': 0.001, 'activation': 'relu'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 3. Avaliação dos Modelos\n",
        "\n",
        "\n",
        "# XGBoost\n",
        "Y_pred_xgb_encoded = best_xgb_model.predict(X_teste)\n",
        "Y_pred_xgb = label_encoder.inverse_transform(Y_pred_xgb_encoded)\n",
        "\n",
        "print(\"XGBoost Accuracy Score:\", accuracy_score(Y_teste, Y_pred_xgb_encoded))\n",
        "print(\"XGBoost Classification Report:\\n\", classification_report(Y_teste, Y_pred_xgb_encoded))\n",
        "\n",
        "# Random Forest\n",
        "Y_pred_rf_encoded = best_rf_model.predict(X_teste)\n",
        "Y_pred_rf = label_encoder.inverse_transform(Y_pred_rf_encoded)\n",
        "\n",
        "print(\"Random Forest Accuracy Score:\", accuracy_score(Y_teste, Y_pred_rf_encoded))\n",
        "print(\"Random Forest Classification Report:\\n\", classification_report(Y_teste, Y_pred_rf_encoded))\n",
        "\n",
        "# MLP\n",
        "Y_pred_mlp_encoded = best_mlp_model.predict(X_teste)\n",
        "Y_pred_mlp = label_encoder.inverse_transform(Y_pred_mlp_encoded)\n",
        "\n",
        "print(\"MLP Accuracy Score:\", accuracy_score(Y_teste, Y_pred_mlp_encoded))\n",
        "print(\"MLP Classification Report:\\n\", classification_report(Y_teste, Y_pred_mlp_encoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK5KcxOwcZlb",
        "outputId": "958d9a80-79e6-44ff-b7f4-5dc49fb9fde7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy Score: 0.799411926858403\n",
            "XGBoost Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.78      0.80      3258\n",
            "           1       0.76      0.77      0.77      4006\n",
            "           2       0.83      0.85      0.84      3619\n",
            "\n",
            "    accuracy                           0.80     10883\n",
            "   macro avg       0.80      0.80      0.80     10883\n",
            "weighted avg       0.80      0.80      0.80     10883\n",
            "\n",
            "Random Forest Accuracy Score: 0.7811265276118717\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.75      0.78      3258\n",
            "           1       0.73      0.76      0.75      4006\n",
            "           2       0.82      0.83      0.82      3619\n",
            "\n",
            "    accuracy                           0.78     10883\n",
            "   macro avg       0.78      0.78      0.78     10883\n",
            "weighted avg       0.78      0.78      0.78     10883\n",
            "\n",
            "MLP Accuracy Score: 0.7083524763392447\n",
            "MLP Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.69      0.71      3258\n",
            "           1       0.67      0.63      0.64      4006\n",
            "           2       0.73      0.82      0.77      3619\n",
            "\n",
            "    accuracy                           0.71     10883\n",
            "   macro avg       0.71      0.71      0.71     10883\n",
            "weighted avg       0.71      0.71      0.71     10883\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Voting Classifier\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Configuração do Voting Classifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', best_xgb_model),  # Usando o modelo XGBoost treinado\n",
        "        ('rf', best_rf_model),    # Usando o modelo Random Forest treinado\n",
        "        ('mlp', best_mlp_model)   # Usando o modelo MLP treinado\n",
        "    ],\n",
        "    voting='hard'  # 'hard' voting classifica a classe com mais votos\n",
        ")\n",
        "\n",
        "# Treinamento do Voting Classifier\n",
        "voting_clf.fit(X_treinamento, Y_treinamento)\n",
        "\n",
        "# Previsão com o Voting Classifier\n",
        "Y_pred_voting_encoded = voting_clf.predict(X_teste)\n",
        "Y_pred_voting = label_encoder.inverse_transform(Y_pred_voting_encoded)\n",
        "\n",
        "# Avaliação do Voting Classifier\n",
        "print(\"Voting Classifier Accuracy Score:\", accuracy_score(Y_teste, Y_pred_voting_encoded))\n",
        "print(\"Voting Classifier Classification Report:\\n\", classification_report(Y_teste, Y_pred_voting_encoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP6f8ZkzXfJx",
        "outputId": "62b8eb8f-abcc-47b8-b375-318da42cb31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Classifier Accuracy Score: 0.789855738307452\n",
            "Voting Classifier Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.77      0.79      3258\n",
            "           1       0.75      0.76      0.75      4006\n",
            "           2       0.82      0.84      0.83      3619\n",
            "\n",
            "    accuracy                           0.79     10883\n",
            "   macro avg       0.79      0.79      0.79     10883\n",
            "weighted avg       0.79      0.79      0.79     10883\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# 5. Validação Cruzada\n",
        "\n",
        "cv_scores_xgb = cross_val_score(best_xgb_model, X, y_encoded, cv=5)\n",
        "print(\"XGBoost Cross-Validation Scores:\", cv_scores_xgb)\n",
        "print(\"XGBoost Mean Cross-Validation Score:\", np.mean(cv_scores_xgb))\n",
        "\n",
        "cv_scores_rf = cross_val_score(best_rf_model, X, y_encoded, cv=5)\n",
        "print(\"Random Forest Cross-Validation Scores:\", cv_scores_rf)\n",
        "print(\"Random Forest Mean Cross-Validation Score:\", np.mean(cv_scores_rf))\n",
        "\n",
        "cv_scores_mlp = cross_val_score(best_mlp_model, X, y_encoded, cv=5)\n",
        "print(\"MLP Cross-Validation Scores:\", cv_scores_mlp)\n",
        "print(\"MLP Mean Cross-Validation Score:\", np.mean(cv_scores_mlp))"
      ],
      "metadata": {
        "id": "VHb7OX3kaif8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c882faf-2158-4075-91c7-1378f1b7ed9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Cross-Validation Scores: [0.79517574 0.80551344 0.79421089 0.80096485 0.79159201]\n",
            "XGBoost Mean Cross-Validation Score: 0.7974913852515507\n",
            "Random Forest Cross-Validation Scores: [0.77725706 0.78842178 0.773949   0.78001378 0.77574087]\n",
            "Random Forest Mean Cross-Validation Score: 0.7790764989662302\n",
            "MLP Cross-Validation Scores: [0.69069607 0.7145417  0.7061337  0.70640937 0.69345279]\n",
            "MLP Mean Cross-Validation Score: 0.7022467263955893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0xjpSe6qBOpC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}